主要步骤与流程：
1、预处理，去除文本的噪声信息
2、中文分词：使用中文分词器为文本分词，去除停用词
3、构建词向量空间：统计文本词频、生成文本的词向量空间
4、权重策略------TF-IDF方法：使用TF-IDF发现特征词，并抽取为反映文档主题的特征
5、分类器：使用算法训练分类器
6、评价分类结构：分类器的测试结果分析


文本预处理：主要是结构化数据
    1、选择处理的文本的范围,适当的范围取决于文本挖掘任务的目标，对于分类或聚类的任务往往将整个文档作为处理单位，对于情感分析、文档懂文摘、信息检索，通常段落或章节更合适
    2、建立分类文本语料库：
        1）训练集语料  http://www.threedweb.cn/thread-1288-1-1.html
        2）测试集语料
    3、文本格式转换
    4、检测句子边界：标记句子的结束


中文分词：小巧高效支持原生python的分词系统 jieba分词。
    1、

